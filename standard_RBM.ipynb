{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets\n",
    "import torchvision.models\n",
    "import torchvision.transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm, tnrange\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle as pkl\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "CUDA_DEVICE = 0\n",
    "\n",
    "if CUDA:\n",
    "    device='cuda'\n",
    "else:\n",
    "    device='cpu'\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define RBM graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "\n",
    "    def __init__(self, n_vis, n_hid, k):\n",
    "        \"\"\"Create a RBM.\"\"\"\n",
    "        super(RBM, self).__init__()\n",
    "        \n",
    "        self.v_bias = nn.Parameter(torch.ones(1, n_vis).to(device))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(1, n_hid).to(device))\n",
    "        self.Weight = nn.Parameter(torch.randn(n_hid, n_vis).to(device))\n",
    "        self.k = k\n",
    "\n",
    "\n",
    "    def v2h(self, v):\n",
    "        return torch.sigmoid(F.linear(v, self.Weight, self.h_bias))\n",
    "\n",
    "    def h2v(self, h):\n",
    "        return torch.sigmoid(F.linear(h, self.Weight.t(), self.v_bias))\n",
    "    \n",
    "    def Fv(self, v):\n",
    "        v_term = torch.matmul(v, self.v_bias.t()).view(len(v))\n",
    "        h_term = torch.sum(F.softplus(F.linear(v, self.Weight, self.h_bias)), dim=1)\n",
    "        return torch.mean(-h_term - v_term)\n",
    "\n",
    "    def energy(self, v, h):\n",
    "        v=v.bernoulli()\n",
    "        h=h.bernoulli()\n",
    "        return -torch.matmul(v, self.v_bias.t())-torch.matmul(torch.matmul(v, self.Weight.t()),h.t())-torch.matmul(h, self.h_bias.t())\n",
    "\n",
    "    def forward(self, v):\n",
    "        h = self.v2h(v)\n",
    "        h = h.bernoulli()\n",
    "        for _ in range(self.k):\n",
    "            v_gibbs = self.h2v(h).to(device)\n",
    "            v_gibbs = v_gibbs.bernoulli()\n",
    "            h = self.v2h(v_gibbs).to(device)\n",
    "            h = h.bernoulli()\n",
    "        return v, v_gibbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to make a train data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "    def __init__(self, dataset):\n",
    "        data_x = dataset\n",
    "        self.x_data = data_x\n",
    "#         self.y_data = data_y\n",
    "\n",
    "    # 총 데이터의 개수를 리턴\n",
    "    def __len__(self): \n",
    "        return len(self.x_data)\n",
    "    # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "    def __getitem__(self, idx): \n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "#         y = torch.FloatTensor([self.y_data[idx]])\n",
    "        return x\n",
    "\n",
    "def data_to_loader(fullconfigs):\n",
    "    fulldata=CustomDataset(fullconfigs)\n",
    "    full_dataset = fulldata\n",
    "    full_loader = torch.utils.data.DataLoader(full_dataset, batch_size)\n",
    "    return full_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_get_data(n_hid, model, lr, train_loader):\n",
    "    # 처음부터 모델을 훈련하려는 경우\n",
    "    if model==0:\n",
    "        rbm=RBM(n_vis, n_hid, k)\n",
    "    # 훈련된 모델을 이어서 훈련하려는 경우\n",
    "    else: \n",
    "        rbm=model\n",
    "    train_loss_list=[]\n",
    "#     train_op = optim.Adam(rbm.parameters(), lr)\n",
    "    train_op = optim.SGD(rbm.parameters(), lr, momentum=0.9)\n",
    "    rbm.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss_epoch = []\n",
    "        for _, (data) in enumerate(train_loader):\n",
    "            data=data.to(device)\n",
    "            v, v_gibbs = rbm(data.view(-1, n_vis))\n",
    "            train_loss = rbm.Fv(v) - rbm.Fv(v_gibbs)\n",
    "            train_loss_epoch.append(train_loss.item())\n",
    "            train_op.zero_grad()\n",
    "            train_loss.backward()\n",
    "            train_op.step()\n",
    "        # val=np.mean(train_loss_epoch)\n",
    "        # train_loss_list.append(val)\n",
    "        # print(epoch, val)\n",
    "        # if epoch>1 and train_loss_list[-1]*train_loss_list[-2]<0:\n",
    "        #     break\n",
    "    rbm=rbm.cpu()\n",
    "    return rbm.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter들을 설정\n",
    "n_vis=9\n",
    "n_hid=2\n",
    "k=1\n",
    "n_epochs=300\n",
    "batch_size=512\n",
    "lr=0.03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 학습 데이터\n",
    "fullconfigs=torch.tensor([[0.,0.,0.,0.,0.,0.,0.,0.,0.], [0.,0.,0.,0.,0.,0.,1.,0.,1.]])\n",
    "# 학습 데이터를 트레인 로더에 담음\n",
    "train_loader=data_to_loader(fullconfigs)\n",
    "# 훈련 결과의 parameter들이 result에 저장됨\n",
    "result=train_and_get_data(n_hid,0,lr,train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('v_bias',\n",
       "              tensor([[-3.4698, -2.9000, -3.0499, -3.8000, -3.2000, -2.8743, -0.1600, -2.7500,\n",
       "                        0.2785]])),\n",
       "             ('h_bias', tensor([[3.6490, 2.6603]])),\n",
       "             ('Weight',\n",
       "              tensor([[ 0.1134, -0.6493, -1.0528, -1.7047, -1.3565, -1.9235, -4.3780, -0.4043,\n",
       "                       -4.2897],\n",
       "                      [-3.0264, -2.1430, -2.3730, -0.9813, -1.6098, -2.1605,  1.9023, -2.3826,\n",
       "                        1.3500]]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
