{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of Copy of Copy of Copy of Copy of Copy of Copy of Copy of Untitled2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/physicaone/loss_IG/blob/master/%5B211029%5DExact_training6_sym.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To4RcII2inSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2278fd0a-1645-4799-f100-38fff707b8cf"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.datasets\n",
        "import torchvision.models\n",
        "import torchvision.transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm, tnrange\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import copy\n",
        "\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "from scipy.stats import entropy\n",
        "CUDA = torch.cuda.is_available()\n",
        "CUDA_DEVICE = 0\n",
        "if CUDA:\n",
        "    device='cuda:1'\n",
        "else:\n",
        "    device='cpu'\n",
        "torch.cuda.is_available()\n",
        "\n",
        "CUDA = torch.cuda.is_available()\n",
        "CUDA_DEVICE = 0\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base='drive/MyDrive'\n",
        "except:\n",
        "    if torch.cuda.device_count()>1:\n",
        "        base='.'\n",
        "    else:\n",
        "        base='Google Drive'\n",
        "\n",
        "if CUDA:\n",
        "    device='cuda:1'\n",
        "else:\n",
        "    device='cpu'\n",
        "torch.cuda.is_available()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPBnJ67MrIEn"
      },
      "source": [
        "def decimal_to_binary(integer, n_hid):\n",
        "    string=bin(int(integer))[2:]\n",
        "    list0=[float(d) for d in string]\n",
        "    while len(list0)<n_hid:\n",
        "        list0=[0.]+list0\n",
        "    return torch.tensor([list0])\n",
        "\n",
        "def Ising_energy(v_list):\n",
        "    L = 3\n",
        "    E_list=[]\n",
        "    for n in range(len(v_list)):\n",
        "        v=v_list[n]\n",
        "        E = 0\n",
        "        for i in range(L):\n",
        "            for j in range(L):\n",
        "                s = v[i,j]\n",
        "                neigh = v[(i+1)%L, j] + v[i,(j+1)%L] + v[(i-1)%L,j] + v[i,(j-1)%L] \n",
        "                E += -neigh * s\n",
        "        E_list.append(E/2)\n",
        "    return np.array(E_list)\n",
        "    \n",
        "class RBM(nn.Module):\n",
        "\n",
        "    def __init__(self, n_vis, n_hid, k):\n",
        "        \"\"\"Create a RBM.\"\"\"\n",
        "        super(RBM, self).__init__()\n",
        "        \n",
        "        self.Weight = nn.Parameter(std*torch.randn(n_hid, n_vis).to(device))\n",
        "        self.k = k\n",
        "\n",
        "\n",
        "    def v2h(self, v):\n",
        "        return torch.tanh(F.linear(v, self.Weight))\n",
        "\n",
        "    def h2v(self, h):\n",
        "        return torch.tanh(F.linear(h, self.Weight.t()))\n",
        "    \n",
        "    def Fv(self, v):\n",
        "        h_term = torch.sum(torch.log(torch.exp(-torch.matmul(v, self.Weight.t()))+torch.exp(torch.matmul(v, self.Weight.t()))), dim=1)\n",
        "        return -h_term \n",
        "\n",
        "    def energy(self, v, h):\n",
        "        v=v.bernoulli()\n",
        "        h=h.bernoulli()\n",
        "        return -torch.matmul(torch.matmul(v, self.Weight.t()),h.t())\n",
        "\n",
        "\n",
        "    def forward(self, v):\n",
        "\n",
        "        return v\n",
        "        \n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset): \n",
        "    def __init__(self, dataset):\n",
        "        data_x = dataset\n",
        "        self.x_data = data_x\n",
        "#         self.y_data = data_y\n",
        "\n",
        "    # 총 데이터의 개수를 리턴\n",
        "    def __len__(self): \n",
        "        return len(self.x_data)\n",
        "    # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
        "    def __getitem__(self, idx): \n",
        "        x = torch.FloatTensor(self.x_data[idx])\n",
        "#         y = torch.FloatTensor([self.y_data[idx]])\n",
        "        return x\n",
        "\n",
        "def data_to_loader(fullconfigs):\n",
        "    fulldata=CustomDataset(fullconfigs)\n",
        "    full_dataset = fulldata\n",
        "    full_loader = torch.utils.data.DataLoader(full_dataset, batch_size)\n",
        "    return full_loader\n",
        "\n",
        "def train_and_get_data(n_hid, model, lr):\n",
        "\n",
        "    rbm=RBM(n_vis, n_hid, k)\n",
        "\n",
        "    train_loss_list=[]\n",
        "#     train_op = optim.Adam(rbm.parameters(), lr)\n",
        "    train_op = optim.SGD(rbm.parameters(), lr, momentum=0.9)\n",
        "    rbm.train()\n",
        "    train_loss_list=[]\n",
        "    model_list=[]\n",
        "    for epoch in tnrange(n_epochs):\n",
        "        Fv=torch.dot(rbm.Fv(v_list_ising2).double(), Pv)\n",
        "        FE=-torch.log(torch.sum(torch.exp(-rbm.Fv(v_list_ising2))))\n",
        "\n",
        "        train_loss = Fv-FE\n",
        "        train_op.zero_grad()\n",
        "        train_loss.backward()\n",
        "        train_op.step()\n",
        "        GE=Fv-FE-S\n",
        "\n",
        "        if epoch in epoch_to_save:\n",
        "            train_loss_list.append(float((train_loss-S).detach().cpu().numpy()))\n",
        "            model_list.append(copy.deepcopy(rbm.cpu().state_dict()))\n",
        "            print('epoch={epoch}, GE={GE}'.format(epoch=epoch, GE=GE))\n",
        "\n",
        "    return model_list, train_loss_list\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu3QpRUBrIHD"
      },
      "source": [
        "# Hyper parameter들을 설정\n",
        "n_vis=9\n",
        "k=1\n",
        "n_epochs=100000\n",
        "lr=0.1\n",
        "std=0.5\n",
        "epoch_to_save=[2**i for i in range(20)]\n",
        "n_epochs=epoch_to_save[-1]+1\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50vRcy9OrIJJ"
      },
      "source": [
        "\n",
        "torch.set_printoptions(precision=10)\n",
        "for n_hid in [12]:\n",
        "    v_list_ising=[]\n",
        "    v_list_ising2=[]\n",
        "    for s in range(2**n_vis):\n",
        "        v=decimal_to_binary(s, n_vis)[0]\n",
        "        v_list_ising.append(np.reshape(v,(3,3))*2-1)\n",
        "        v_list_ising2.append(v)\n",
        "    v_list_ising2=torch.stack(v_list_ising2).to(device)*2-1\n",
        "\n",
        "    for T in [16]:\n",
        "        bf_list=np.exp(-Ising_energy(v_list_ising)/T)\n",
        "        S=entropy(bf_list)\n",
        "        Pv=torch.tensor(bf_list/sum(bf_list)).to(device).double()\n",
        "\n",
        "        model_dict={}\n",
        "        error_dict={}\n",
        "        for m in range(10):\n",
        "            model0, loss=train_and_get_data(n_hid, 0, lr=0.1)\n",
        "            model_dict[str(m)]=model0\n",
        "            error_dict[str(m)]=loss\n",
        "        with open('{base}/loss_IG/3*3/Exact_state_dict/model_n_hid={n_hid}_T={T}_sym.pkl'.format(base=base, n_hid=n_hid, T=T), 'wb') as f:\n",
        "            pkl.dump(model_dict, f)\n",
        "        with open('{base}/loss_IG/3*3/Exact_error/error_n_hid={n_hid}_T={T}_sym.pkl'.format(base=base, n_hid=n_hid, T=T), 'wb') as f:\n",
        "            pkl.dump(error_dict, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kx-P8t9rISQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TEBRS4arIUQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}