{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[210815]PT_IG_loss.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP03cJOalhl2DMKSds/nytm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/physicaone/loss_IG/blob/master/%5B210815%5DPT_IG_loss2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt7BmkBk-oKR",
        "outputId": "6d159814-b5c9-4d14-da24-b20e2e7a2ab2"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.datasets\n",
        "import torchvision.models\n",
        "import torchvision.transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm, tnrange\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import random\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "from scipy.stats import entropy\n",
        "CUDA = torch.cuda.is_available()\n",
        "CUDA_DEVICE = 0\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base='drive/MyDrive'\n",
        "except:\n",
        "    if torch.cuda.device_count()>1:\n",
        "        base='.'\n",
        "    else:\n",
        "        base='Google Drive'\n",
        "\n",
        "if CUDA:\n",
        "    device='cuda'\n",
        "else:\n",
        "    device='cpu'\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9bHJ2DF-oH-"
      },
      "source": [
        "def decimal_to_binary(integer, n_hid):\n",
        "    string=bin(int(integer))[2:]\n",
        "    list0=[float(d) for d in string]\n",
        "    while len(list0)<n_hid:\n",
        "        list0=[0.]+list0\n",
        "    return torch.tensor([list0])\n",
        "\n",
        "def binary_to_decimal(list0):\n",
        "    value=0\n",
        "    list0=list0.tolist()\n",
        "    for i in range(len(list0)):\n",
        "        value+=list0[-i-1]*2**(i)\n",
        "    return int(value)\n",
        "\n",
        "def Ising_energy(v_list):\n",
        "    L = 3\n",
        "    E_list=[]\n",
        "    for n in range(len(v_list)):\n",
        "        v=v_list[n]\n",
        "        E = 0\n",
        "        for i in range(L):\n",
        "            for j in range(L):\n",
        "                s = v[i,j]\n",
        "                neigh = v[(i+1)%L, j] + v[i,(j+1)%L] + v[(i-1)%L,j] + v[i,(j-1)%L] \n",
        "                E += -neigh * s\n",
        "        E_list.append(E/2)\n",
        "    return np.array(E_list)\n",
        "    \n",
        "class RBM(nn.Module):\n",
        "\n",
        "    def __init__(self, n_vis, n_hid, k):\n",
        "        \"\"\"Create a RBM.\"\"\"\n",
        "        super(RBM, self).__init__()\n",
        "        \n",
        "        self.v_bias = nn.Parameter(torch.ones(1, n_vis).to(device))\n",
        "        self.h_bias = nn.Parameter(torch.zeros(1, n_hid).to(device))\n",
        "        self.Weight = nn.Parameter(torch.randn(n_hid, n_vis).to(device))\n",
        "        self.k = k\n",
        "\n",
        "\n",
        "    def v2h(self, v, beta):\n",
        "        return torch.sigmoid(F.linear(v, self.Weight, self.h_bias)*beta).detach()\n",
        "\n",
        "    def h2v(self, h, beta):\n",
        "        return torch.sigmoid(F.linear(h, self.Weight.t(), self.v_bias)*beta).detach()\n",
        "    \n",
        "    def Fv(self, v):\n",
        "        v_term = torch.matmul(v, self.v_bias.t()).view(len(v)).detach()\n",
        "        h_term = torch.sum(F.softplus(F.linear(v, self.Weight, self.h_bias)), dim=1).detach()\n",
        "        return -h_term -v_term\n",
        "\n",
        "    def energy(self, v, h):\n",
        "        v=v.bernoulli().detach()\n",
        "        h=h.bernoulli().detach()\n",
        "        return -torch.matmul(v, self.v_bias.t())-torch.matmul(torch.matmul(v, self.Weight.t()),h.t())-torch.matmul(h, self.h_bias.t()).detach()\n",
        "    \n",
        "    def Energy_GPU2(self, v_list0, h_list0):\n",
        "        if CUDA:\n",
        "            n_split=torch.cuda.device_count()\n",
        "        else:\n",
        "            n_split=1\n",
        "        e_list=[]\n",
        "        m_split=4\n",
        "        for j in range(m_split):\n",
        "            v_list1=torch.stack(list(v_list0[j*int(len(v_list0)/m_split):(j+1)*int(len(v_list0)/m_split)])).detach()\n",
        "            h_list1=torch.stack(list(h_list0[j*int(len(h_list0)/m_split):(j+1)*int(len(h_list0)/m_split)])).detach()\n",
        "            vs=[]\n",
        "            hs=[]\n",
        "            for i in range(n_split):\n",
        "                v_list2=torch.stack(list(v_list1[i*int(len(v_list1)/n_split):(i+1)*int(len(v_list1)/n_split)])).detach()\n",
        "                h_list2=torch.stack(list(h_list1[i*int(len(h_list1)/n_split):(i+1)*int(len(h_list1)/n_split)])).detach()\n",
        "                if CUDA:\n",
        "                    v_list2=v_list2.to(device='cuda:' + str(i)).view(len(v_list2), n_vis)\n",
        "                    h_list2=h_list2.to(device='cuda:' + str(i)).view(len(h_list2), n_hid)\n",
        "                else:\n",
        "                    None\n",
        "                vs.append(v_list2)\n",
        "                hs.append(h_list2)\n",
        "            for i in range(n_split): \n",
        "                if CUDA:\n",
        "                    a=self.v_bias.to(device='cuda:' + str(i)).view(n_vis)\n",
        "                    b=self.h_bias.to(device='cuda:' + str(i)).view(n_hid)\n",
        "                    W=self.Weight.to(device='cuda:' + str(i)).view(n_hid, n_vis)\n",
        "                    e=(-torch.matmul(vs[i].float(), a)-torch.diagonal(torch.matmul(torch.matmul(vs[i].float(), W.t()), hs[i].float().t()))-torch.matmul(hs[i].float(), b)).to('cuda:0')\n",
        "                    e_list.append(e)\n",
        "                else:\n",
        "                    a=self.v_bias.view(n_vis)\n",
        "                    b=self.h_bias.view(n_hid)\n",
        "                    W=self.Weight.view(n_hid, n_vis)\n",
        "                    e=(-torch.matmul(vs[i].float(), a)-torch.diagonal(torch.matmul(torch.matmul(vs[i].float(), W.t()), hs[i].float().t()))-torch.matmul(hs[i].float(), b))\n",
        "                    e_list.append(e)\n",
        "        return torch.stack(e_list).view(len(v_list0)).detach()\n",
        "    \n",
        "# 이 함수는 PT에 사용되는 transition 확률을 계산합니다.\n",
        "def swap_prob(i,j, model, list00, list11):\n",
        "    v1=torch.tensor(list00[i]).view(1,n_vis)\n",
        "    v2=torch.tensor(list00[j]).view(1,n_vis)\n",
        "    h1=torch.tensor(list11[i]).view(1,n_hid)\n",
        "    h2=torch.tensor(list11[j]).view(1,n_hid)\n",
        "    beta1=beta_list[i]\n",
        "    beta2=beta_list[j]\n",
        "    return torch.exp((beta2-beta1)*(model.energy(v2, h2)-model.energy(v1, h1)))\n",
        "\n",
        "# 이 함수는 tansition 확률에 의거, swap을 수행합니다.\n",
        "def swap(list0, list1, model):\n",
        "    k=np.random.randint(0, len(list0)-1)\n",
        "    combination=[k, k+1]\n",
        "    if swap_prob(combination[0], combination[1], model, list0, list1)>=np.random.rand():\n",
        "        a=list0[combination[0]].clone()\n",
        "        b=list0[combination[1]].clone() \n",
        "        list0[combination[0]]=b\n",
        "        list0[combination[1]]=a\n",
        "        \n",
        "        c=list1[combination[0]].clone()\n",
        "        d=list1[combination[1]].clone() \n",
        "        list1[combination[0]]=d\n",
        "        list1[combination[1]]=c\n",
        "    else: None\n",
        "#     return list0, list1\n",
        "#     combinations=list(itertools.combinations(list(range(len(list0))), 2))\n",
        "#     for k in range(len(combinations)):\n",
        "#         if swap_prob(combinations[k][1], combinations[k][0])>=np.random.rand():\n",
        "#             list0[combinations[k][0]]=list0[combinations[k][1]]; list0[combinations[k][1]]=list0[combinations[k][0]]\n",
        "#         else: None\n",
        "#     return list0\n",
        "\n",
        "def P_h(list0):\n",
        "    config_count={}\n",
        "    for i in range(len(list0)):\n",
        "        config_count[str(list0[i])]=0\n",
        "    for i in range(len(list0)):\n",
        "        config_count[str(list0[i])]+=1\n",
        "    return config_count\n",
        "\n",
        "def prod(L):\n",
        "    p=1\n",
        "    for i in L:\n",
        "        p= i * p\n",
        "    return p\n",
        "\n",
        "# def Estimate_Z(model0, states):\n",
        "#     Z=0\n",
        "#     for i in range(len(states[0])):\n",
        "#         Z+=torch.exp(-model0.energy2(states[0][i], states[1][i])).detach()\n",
        "#     return float(Z.detach().numpy())\n",
        "\n",
        "def get_hist(list00, color='red'):\n",
        "    bins=range(int(min(list00)-30), int(max(list00)+30), 1)\n",
        "    y1,x1,_ = plt.hist(list00, bins = bins, histtype='step', color=color)\n",
        "    x1 = 0.5*(x1[1:]+x1[:-1])\n",
        "    return x1, y1\n",
        "\n",
        "def flatten_list(list0):\n",
        "    flattened = [val for sublist in list0 for val in sublist]\n",
        "    return flattened\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0Ysh2ZQ-oFe"
      },
      "source": [
        "\n",
        "def Entropy(fullconfigs):\n",
        "    config_count={} # 각 hidden layer state 갯수 파악 (k)\n",
        "    for i in range(len(fullconfigs)):\n",
        "        config_count[str(fullconfigs[i])]=0\n",
        "    for i in range(len(fullconfigs)):\n",
        "        config_count[str(fullconfigs[i])]+=1\n",
        "\n",
        "    listk=[]\n",
        "    for i in range(len(list(config_count.values()))):\n",
        "        listk.append(int(list(config_count.values())[i]))\n",
        "    listmk=[]\n",
        "    kcount={} # 갯수의 갯수 파악 (m_k)\n",
        "    for i in range(len(listk)):\n",
        "        kcount[listk[i]]=0\n",
        "    for i in range(len(listk)):\n",
        "        kcount[listk[i]]+=1\n",
        "    for i in range(len(kcount)):\n",
        "        listmk.append(kcount[sorted(list(kcount))[i]])\n",
        "    x,y= sorted(list(kcount)), listmk\n",
        "\n",
        "    N=len(fullconfigs)\n",
        "    H_s=0\n",
        "    for i in range(len(x)):\n",
        "        H_s-=(x[i]*y[i]/N)*np.log(x[i]/N)\n",
        "    return H_s\n",
        "def Energy(model0_dict, v_list, h_list):\n",
        "    a=model0_dict['v_bias'].detach()\n",
        "    b=model0_dict['h_bias'].detach()\n",
        "    W=model0_dict['Weight'].detach()\n",
        "    values=[]\n",
        "    for i in range(len(v_list)):\n",
        "        e=-np.matmul(v_list[i], a.t())-np.matmul(np.matmul(v_list[i], W.t()), h_list[i].t())-np.matmul(h_list[i], b.t())\n",
        "        values.append(e.detach())\n",
        "    return float(np.mean(values))\n",
        "    \n",
        "# function to save every T samples\n",
        "def sampling_with_PT(fullmodel, eq_step, n_step):\n",
        "    # states for full model\n",
        "    hidden_states_now=[decimal_to_binary(2**n_hid-1, n_hid)]*len(beta_list)\n",
        "    visible_states_now=[1.]*len(beta_list)\n",
        "\n",
        "    hidden_list=[]\n",
        "    visible_list=[]\n",
        "    \n",
        "    # equilibrium steps for full model\n",
        "    for step in range(eq_step):\n",
        "        for i in range(len(beta_list)):\n",
        "            visible_states_now[i]=fullmodel.h2v(hidden_states_now[i].to(device), beta_list[i]).bernoulli().detach()\n",
        "            hidden_states_now[i]=fullmodel.v2h(visible_states_now[i].to(device), beta_list[i]).bernoulli().detach()\n",
        "\n",
        "    # Tasks with PT\n",
        "    for step in range(n_step):\n",
        "        hidden_tmp=[]\n",
        "        visible_tmp=[]\n",
        "        for i in range(len(beta_list)):\n",
        "            # Gibbs sampling of fu\n",
        "            visible_states_now[i]=fullmodel.h2v(hidden_states_now[i].to(device), beta_list[i]).bernoulli().detach()\n",
        "            hidden_states_now[i]=fullmodel.v2h(visible_states_now[i].to(device), beta_list[i]).bernoulli().detach()\n",
        "\n",
        "            hidden_tmp.append(int(binary_to_decimal(hidden_states_now[i].view(n_hid))))\n",
        "            visible_tmp.append(int(binary_to_decimal(visible_states_now[i].view(n_vis))))\n",
        "        swap(visible_states_now, hidden_states_now, fullmodel)\n",
        "        hidden_list.append(hidden_tmp)\n",
        "        visible_list.append(visible_tmp)\n",
        "    return visible_list, hidden_list\n",
        "\n",
        "def Curly_W(model_dict, v, h):\n",
        "    w=[]\n",
        "    for i in range(len(beta_list)-1):\n",
        "        w.append(beta_list[i]*Energy(model_dict, decimal_to_binary(v[i+1], n_vis), decimal_to_binary(h[i+1], n_hid))\n",
        "        -beta_list[i+1]*Energy(model_dict, decimal_to_binary(v[i+1],n_vis), decimal_to_binary(h[i+1],n_hid)))\n",
        "    return w\n",
        "\n",
        "def Curly_W_tilde(model_dict, v, h):\n",
        "    w_t=[]\n",
        "    for i in range(1,len(beta_list)):\n",
        "        w_t.append(beta_list[i-1]*Energy(model_dict, decimal_to_binary(v[i-1], n_vis), decimal_to_binary(h[i-1], n_hid))\n",
        "        -beta_list[i]*Energy(model_dict, decimal_to_binary(v[i-1],n_vis), decimal_to_binary(h[i-1],n_hid)))\n",
        "    return w_t\n",
        "\n",
        "def AISPT(model_dict, v_list, h_list):\n",
        "    r=len(v_list)\n",
        "    C=0\n",
        "    for n in range(r):\n",
        "        C+=np.exp(-np.sum(Curly_W(model_dict, v_list[n], h_list[n])))\n",
        "    C=C/r\n",
        "    C=np.log(C)\n",
        "    return -C -np.log(2**(n_vis+n_hid)/100000)-np.log(100000)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXfmZ6pi-oC9"
      },
      "source": [
        "n_hid_list=[32]\n",
        "T_list=[1.47,1.78,2.3,5.2,16]\n",
        "n_beta=101\n",
        "n_step=10000\n",
        "eq_step=1000\n",
        "beta_list=torch.tensor(np.linspace(1,0,n_beta).astype(float)).to(device)\n",
        "n_vis=9\n",
        "lr=0.05\n",
        "k=1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Jyw8Lo-oAd"
      },
      "source": [
        "for n_hid in n_hid_list:\n",
        "    v_list_ising=[]\n",
        "    v_list_ising2=[]\n",
        "    for s in range(2**n_vis):\n",
        "        v=decimal_to_binary(s, n_vis)[0]\n",
        "        v_list_ising.append(np.reshape(v,(3,3))*2-1)\n",
        "        v_list_ising2.append(v)\n",
        "    v_list_ising2=torch.stack(v_list_ising2).to(device)  \n",
        "    for T in tqdm(T_list):\n",
        "        bf_list=np.exp(-Ising_energy(v_list_ising)/T)\n",
        "        S=entropy(bf_list)\n",
        "        Pv=torch.tensor(bf_list/sum(bf_list)).to(device)\n",
        "        \n",
        "        IG_loss_list=[]\n",
        "        models=pd.read_pickle('{base}/loss_IG/3*3/state_dict/model_n_hid={n_hid}_T={T}_lr={lr}_1.pkl'.format(base=base, n_hid=n_hid, T=T, lr=lr))\n",
        "        for i in range(len(models)):\n",
        "            rbm=RBM(n_vis, n_hid, k)\n",
        "            rbm.load_state_dict(models[i])\n",
        "            v_list, h_list=sampling_with_PT(rbm, eq_step, n_step)\n",
        "            IG_loss_list.append(torch.dot(rbm.Fv(v_list_ising2), Pv)-AISPT(models[i], v_list, h_list)-S)\n",
        "        with open('{base}/loss_IG/3*3/loss/IG_loss_n_hid={n_hid}_T={T}_lr={lr}_1_PT{n_beta}.pkl'.format(base=base, n_hid=n_hid, T=T, lr=lr, n_beta=n_beta), 'wb') as f:\n",
        "            pkl.dump(np.array(IG_loss_list), f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "999uDVxX-n36"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}